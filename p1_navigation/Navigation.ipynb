{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the first project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893).\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing some necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only necessary when executing this notebook on the Udacity cloud\n",
    "#!pip -q install ../python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Banana.app\"`\n",
    "- **Windows** (x86): `\"path/to/Banana_Windows_x86/Banana.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Banana_Windows_x86_64/Banana.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Banana_Linux/Banana.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Banana_Linux/Banana.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Banana.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Banana.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "# Standalone machine\n",
    "#env = UnityEnvironment( os.path.join( os.environ['HOME'], 'Python/rl/udadrl/data/Banana_Linux/Banana.x86_64' ) ) # Visible (Best 4 testing)\n",
    "env = UnityEnvironment( os.path.join( os.environ['HOME'], 'Python/rl/udadrl/data/Banana_Linux_NoVis/Banana.x86_64' ) ) # Invisible (Best 4 training)\n",
    "\n",
    "# Udacity cloud\n",
    "#env = UnityEnvironment( file_name=\"/data/Banana_Linux_NoVis/Banana.x86_64\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "The simulation contains a single agent that navigates a large environment.  At each time step, it has four actions at its disposal:\n",
    "- `0` - walk forward \n",
    "- `1` - walk backward\n",
    "- `2` - turn left\n",
    "- `3` - turn right\n",
    "\n",
    "The state space has `37` dimensions and contains the agent's velocity, along with ray-based perception of objects around agent's forward direction.  A reward of `+1` is provided for collecting a yellow banana, and a reward of `-1` is provided for collecting a blue banana. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "States look like: [1.         0.         0.         0.         0.84408134 0.\n",
      " 0.         1.         0.         0.0748472  0.         1.\n",
      " 0.         0.         0.25755    1.         0.         0.\n",
      " 0.         0.74177343 0.         1.         0.         0.\n",
      " 0.25854847 0.         0.         1.         0.         0.09355672\n",
      " 0.         1.         0.         0.         0.31969345 0.\n",
      " 0.        ]\n",
      "States have length: 37\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action (uniformly) at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dql_agent import Agent\n",
    "from math import tanh\n",
    "\n",
    "\n",
    "#agent = Agent(state_size, action_size, time.time())\n",
    "agent = Agent(state_size, action_size)\n",
    "\n",
    "# Helper functions\n",
    "def get_time_string():\n",
    "    return time.strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "def get_epsilon_i(num_episodes, epsilon_min = 0.01, evaluate = True): # evaluate is True by default coz tanh doesn't work well with Sarsa\n",
    "        \"\"\" Getting a nice numpy array with epsilon values for every episode according to\n",
    "        epsilon_i = epsilon_min+(1.0-epsilon_min)*(1-tanh(10*(i/num_episodes))) \"\"\"\n",
    "        if evaluate:\n",
    "            epsilon = [1.0 / (i+1) for i in range(num_episodes+10)]\n",
    "        else:\n",
    "            epsilon = [epsilon_min+(1.0-epsilon_min)*(1-tanh(10*(i/num_episodes))) for i in range(num_episodes+10)]\n",
    "        return epsilon\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  100; Score:   1.0; Epsilon: 0.9510; Mean (100): -0.01 *\n",
      "Epoch:  200; Score:   0.0; Epsilon: 0.9018; Mean (100): +0.22 *\n",
      "Epoch:  300; Score:   3.0; Epsilon: 0.8531; Mean (100): +0.53 *\n",
      "Epoch:  400; Score:   0.0; Epsilon: 0.8051; Mean (100): +0.97 *\n",
      "Epoch:  500; Score:   2.0; Epsilon: 0.7580; Mean (100): +1.74 *\n",
      "Epoch:  600; Score:   2.0; Epsilon: 0.7121; Mean (100): +2.12 *\n",
      "Epoch:  700; Score:   3.0; Epsilon: 0.6674; Mean (100): +3.13 *\n",
      "Epoch:  800; Score:   4.0; Epsilon: 0.6243; Mean (100): +2.94 *\n",
      "Epoch:  900; Score:   5.0; Epsilon: 0.5827; Mean (100): +4.29 *\n",
      "Epoch: 1000; Score:   4.0; Epsilon: 0.5429; Mean (100): +4.89 *\n",
      "Epoch: 1100; Score:   5.0; Epsilon: 0.5049; Mean (100): +5.29 *\n",
      "Epoch: 1200; Score:  13.0; Epsilon: 0.4687; Mean (100): +6.30 *\n",
      "Epoch: 1300; Score:  11.0; Epsilon: 0.4344; Mean (100): +6.80 *\n",
      "Epoch: 1400; Score:   7.0; Epsilon: 0.4020; Mean (100): +6.89 *\n",
      "Epoch: 1500; Score:   9.0; Epsilon: 0.3715; Mean (100): +7.75 *\n",
      "Epoch: 1600; Score:   5.0; Epsilon: 0.3429; Mean (100): +8.33 *\n",
      "Epoch: 1700; Score:   7.0; Epsilon: 0.3161; Mean (100): +8.72 *\n",
      "Epoch: 1800; Score:  10.0; Epsilon: 0.2911; Mean (100): +9.07 *\n",
      "Epoch: 1900; Score:   5.0; Epsilon: 0.2678; Mean (100): +10.19 *\n",
      "Epoch: 2000; Score:  11.0; Epsilon: 0.2462; Mean (100): +10.42 *\n",
      "Epoch: 2100; Score:   8.0; Epsilon: 0.2262; Mean (100): +11.27 *\n",
      "Epoch: 2200; Score:   9.0; Epsilon: 0.2077; Mean (100): +10.52 *\n",
      "Epoch: 2300; Score:  16.0; Epsilon: 0.1906; Mean (100): +10.84 *\n",
      "Epoch: 2400; Score:  13.0; Epsilon: 0.1748; Mean (100): +11.30 *\n",
      "Epoch: 2500; Score:  18.0; Epsilon: 0.1603; Mean (100): +11.47 *\n",
      "Epoch: 2600; Score:  15.0; Epsilon: 0.1470; Mean (100): +10.99 *\n",
      "Epoch: 2700; Score:  12.0; Epsilon: 0.1348; Mean (100): +12.23 *\n",
      "Epoch: 2800; Score:   3.0; Epsilon: 0.1236; Mean (100): +11.80 *\n",
      "Epoch: 2900; Score:  16.0; Epsilon: 0.1134; Mean (100): +12.81 *\n",
      "Epoch: 3000; Score:   3.0; Epsilon: 0.1040; Mean (100): +12.94 *\n",
      "Epoch: 3100; Score:  19.0; Epsilon: 0.0954; Mean (100): +12.69 *\n",
      "Epoch: 3200; Score:  15.0; Epsilon: 0.0876; Mean (100): +12.98 *\n",
      "Epoch: 3300; Score:  13.0; Epsilon: 0.0805; Mean (100): +13.46 *\n",
      "Epoch: 3400; Score:  17.0; Epsilon: 0.0740; Mean (100): +13.64 *\n",
      "Epoch: 3500; Score:  16.0; Epsilon: 0.0681; Mean (100): +12.49 *\n",
      "Epoch: 3600; Score:   8.0; Epsilon: 0.0627; Mean (100): +13.29 *\n",
      "Epoch: 3700; Score:  17.0; Epsilon: 0.0578; Mean (100): +13.82 *\n",
      "Epoch: 3800; Score:  16.0; Epsilon: 0.0534; Mean (100): +14.83 *\n",
      "Epoch: 3900; Score:  18.0; Epsilon: 0.0493; Mean (100): +15.79 *\n",
      "Epoch: 4000; Score:  14.0; Epsilon: 0.0456; Mean (100): +13.94 *\n",
      "Epoch: 4100; Score:  20.0; Epsilon: 0.0423; Mean (100): +12.88 *\n",
      "Epoch: 4200; Score:   9.0; Epsilon: 0.0393; Mean (100): +14.67 *\n",
      "Epoch: 4300; Score:  11.0; Epsilon: 0.0365; Mean (100): +14.82 *\n",
      "Epoch: 4400; Score:  18.0; Epsilon: 0.0340; Mean (100): +14.98 *\n",
      "Epoch: 4500; Score:  15.0; Epsilon: 0.0318; Mean (100): +14.98 *\n",
      "Epoch: 4600; Score:  16.0; Epsilon: 0.0297; Mean (100): +13.63 *\n",
      "Epoch: 4700; Score:  18.0; Epsilon: 0.0279; Mean (100): +14.49 *\n",
      "Epoch: 4800; Score:  14.0; Epsilon: 0.0262; Mean (100): +13.28 *\n",
      "Epoch: 4900; Score:  15.0; Epsilon: 0.0246; Mean (100): +15.24 *\n",
      "Epoch: 5000; Score:  21.0; Epsilon: 0.0233; Mean (100): +15.32 *\n",
      "Epoch: 5100; Score:  16.0; Epsilon: 0.0220; Mean (100): +14.69 *\n",
      "Epoch: 5200; Score:  13.0; Epsilon: 0.0209; Mean (100): +14.84 *\n",
      "Epoch: 5300; Score:  17.0; Epsilon: 0.0198; Mean (100): +13.40 *\n",
      "Epoch: 5400; Score:   3.0; Epsilon: 0.0189; Mean (100): +13.69 *\n",
      "Epoch: 5500; Score:   9.0; Epsilon: 0.0181; Mean (100): +14.77 *\n",
      "Epoch: 5600; Score:  18.0; Epsilon: 0.0173; Mean (100): +14.91 *\n",
      "Epoch: 5700; Score:  19.0; Epsilon: 0.0166; Mean (100): +15.44 *\n",
      "Epoch: 5800; Score:  17.0; Epsilon: 0.0160; Mean (100): +15.50 *\n",
      "Epoch: 5900; Score:  16.0; Epsilon: 0.0154; Mean (100): +15.42 *\n",
      "Epoch: 6000; Score:  12.0; Epsilon: 0.0149; Mean (100): +14.26 *\n",
      "Epoch: 6100; Score:  14.0; Epsilon: 0.0144; Mean (100): +14.50 *\n",
      "Epoch: 6200; Score:  16.0; Epsilon: 0.0140; Mean (100): +13.38 *\n",
      "Epoch: 6300; Score:  16.0; Epsilon: 0.0136; Mean (100): +14.72 *\n",
      "Epoch: 6400; Score:  16.0; Epsilon: 0.0133; Mean (100): +14.80 *\n",
      "Epoch: 6500; Score:  23.0; Epsilon: 0.0130; Mean (100): +13.57 *\n",
      "Epoch: 6600; Score:  16.0; Epsilon: 0.0127; Mean (100): +14.41 *\n",
      "Epoch: 6700; Score:  18.0; Epsilon: 0.0124; Mean (100): +15.75 *\n",
      "Epoch: 6800; Score:  18.0; Epsilon: 0.0122; Mean (100): +14.33 *\n",
      "Epoch: 6900; Score:  16.0; Epsilon: 0.0120; Mean (100): +15.34 *\n",
      "Epoch: 7000; Score:  16.0; Epsilon: 0.0118; Mean (100): +14.41 *\n",
      "Epoch: 7100; Score:   4.0; Epsilon: 0.0116; Mean (100): +14.69 *\n",
      "Epoch: 7200; Score:   8.0; Epsilon: 0.0115; Mean (100): +13.60 *\n",
      "Epoch: 7300; Score:  20.0; Epsilon: 0.0113; Mean (100): +14.41 *\n",
      "Epoch: 7400; Score:  22.0; Epsilon: 0.0112; Mean (100): +15.01 *\n",
      "Epoch: 7500; Score:  15.0; Epsilon: 0.0111; Mean (100): +15.62 *\n",
      "Epoch: 7600; Score:  23.0; Epsilon: 0.0110; Mean (100): +15.82 *\n",
      "Epoch: 7700; Score:  14.0; Epsilon: 0.0109; Mean (100): +16.50 *\n",
      "Epoch: 7800; Score:  12.0; Epsilon: 0.0108; Mean (100): +14.08 *\n",
      "Epoch: 7900; Score:  21.0; Epsilon: 0.0107; Mean (100): +14.10 *\n",
      "Epoch: 8000; Score:  16.0; Epsilon: 0.0107; Mean (100): +14.54 *\n",
      "Epoch: 8100; Score:  15.0; Epsilon: 0.0106; Mean (100): +13.88 *\n",
      "Epoch: 8200; Score:  13.0; Epsilon: 0.0105; Mean (100): +15.59 *\n",
      "Epoch: 8300; Score:  16.0; Epsilon: 0.0105; Mean (100): +14.31 *\n",
      "Epoch: 8400; Score:   4.0; Epsilon: 0.0104; Mean (100): +14.55 *\n",
      "Epoch: 8500; Score:  19.0; Epsilon: 0.0104; Mean (100): +14.19 *\n",
      "Epoch: 8600; Score:  18.0; Epsilon: 0.0104; Mean (100): +15.12 *\n",
      "Epoch: 8700; Score:  11.0; Epsilon: 0.0103; Mean (100): +14.18 *\n",
      "Epoch: 8800; Score:  19.0; Epsilon: 0.0103; Mean (100): +14.39 *\n",
      "Epoch: 8900; Score:   6.0; Epsilon: 0.0103; Mean (100): +13.21 *\n",
      "Epoch: 9000; Score:  12.0; Epsilon: 0.0102; Mean (100): +13.52 *\n",
      "Epoch: 9100; Score:   6.0; Epsilon: 0.0102; Mean (100): +15.17 *\n",
      "Epoch: 9200; Score:   6.0; Epsilon: 0.0102; Mean (100): +14.70 *\n",
      "Epoch: 9300; Score:  20.0; Epsilon: 0.0102; Mean (100): +14.57 *\n",
      "Epoch: 9400; Score:  19.0; Epsilon: 0.0102; Mean (100): +14.59 *\n",
      "Epoch: 9500; Score:  15.0; Epsilon: 0.0101; Mean (100): +14.81 *\n",
      "Epoch: 9600; Score:  14.0; Epsilon: 0.0101; Mean (100): +15.32 *\n",
      "Epoch: 9700; Score:   9.0; Epsilon: 0.0101; Mean (100): +14.70 *\n",
      "Epoch: 9800; Score:  11.0; Epsilon: 0.0101; Mean (100): +14.93 *\n",
      "Epoch: 9900; Score:  14.0; Epsilon: 0.0101; Mean (100): +15.27 *\n",
      "Epoch:10000; Score:   9.0; Epsilon: 0.0101; Mean (100): +14.32 *\n",
      "Epoch:10100; Score:  12.0; Epsilon: 0.0101; Mean (100): +15.69 *\n",
      "Epoch:10200; Score:  11.0; Epsilon: 0.0101; Mean (100): +15.52 *\n",
      "Epoch:10300; Score:  11.0; Epsilon: 0.0101; Mean (100): +14.01 *\n",
      "Epoch:10400; Score:  19.0; Epsilon: 0.0101; Mean (100): +14.11 *\n",
      "Epoch:10500; Score:  12.0; Epsilon: 0.0101; Mean (100): +14.04 *\n",
      "Epoch:10600; Score:  15.0; Epsilon: 0.0100; Mean (100): +14.55 *\n",
      "Epoch:10700; Score:  21.0; Epsilon: 0.0100; Mean (100): +15.18 *\n",
      "Epoch:10800; Score:  18.0; Epsilon: 0.0100; Mean (100): +14.61 *\n",
      "Epoch:10900; Score:  18.0; Epsilon: 0.0100; Mean (100): +14.24 *\n",
      "Epoch:11000; Score:   9.0; Epsilon: 0.0100; Mean (100): +14.47 *\n",
      "Epoch:11100; Score:  16.0; Epsilon: 0.0100; Mean (100): +15.02 *\n",
      "Epoch:11200; Score:  14.0; Epsilon: 0.0100; Mean (100): +14.48 *\n",
      "Epoch:11300; Score:  15.0; Epsilon: 0.0100; Mean (100): +13.81 *\n",
      "Epoch:11400; Score:  14.0; Epsilon: 0.0100; Mean (100): +14.41 *\n",
      "Epoch:11500; Score:  16.0; Epsilon: 0.0100; Mean (100): +14.12 *\n",
      "Epoch:11600; Score:  19.0; Epsilon: 0.0100; Mean (100): +14.27 *\n",
      "Epoch:11700; Score:  16.0; Epsilon: 0.0100; Mean (100): +15.67 *\n",
      "Epoch:11800; Score:  16.0; Epsilon: 0.0100; Mean (100): +14.97 *\n",
      "Epoch:11900; Score:  13.0; Epsilon: 0.0100; Mean (100): +15.30 *\n",
      "Epoch:12000; Score:  19.0; Epsilon: 0.0100; Mean (100): +13.96 *\n",
      "Epoch:12100; Score:  13.0; Epsilon: 0.0100; Mean (100): +14.42 *\n",
      "Epoch:12200; Score:  17.0; Epsilon: 0.0100; Mean (100): +15.29 *\n",
      "Epoch:12300; Score:  11.0; Epsilon: 0.0100; Mean (100): +13.50 *\n",
      "Epoch:12400; Score:  18.0; Epsilon: 0.0100; Mean (100): +15.48 *\n",
      "Epoch:12500; Score:  13.0; Epsilon: 0.0100; Mean (100): +14.86 *\n",
      "Epoch:12600; Score:  12.0; Epsilon: 0.0100; Mean (100): +14.65 *\n",
      "Epoch:12700; Score:  14.0; Epsilon: 0.0100; Mean (100): +15.15 *\n",
      "Epoch:12800; Score:  17.0; Epsilon: 0.0100; Mean (100): +14.63 *\n",
      "Epoch:12900; Score:  20.0; Epsilon: 0.0100; Mean (100): +15.04 *\n",
      "Epoch:13000; Score:  14.0; Epsilon: 0.0100; Mean (100): +14.84 *\n",
      "Epoch:13100; Score:  12.0; Epsilon: 0.0100; Mean (100): +14.35 *\n",
      "Epoch:13200; Score:  10.0; Epsilon: 0.0100; Mean (100): +13.97 *\n",
      "Epoch:13300; Score:  25.0; Epsilon: 0.0100; Mean (100): +13.88 *\n",
      "Epoch:13400; Score:  16.0; Epsilon: 0.0100; Mean (100): +14.16 *\n",
      "Epoch:13500; Score:  18.0; Epsilon: 0.0100; Mean (100): +14.77 *\n",
      "Epoch:13600; Score:  23.0; Epsilon: 0.0100; Mean (100): +16.25 *\n",
      "Epoch:13700; Score:  10.0; Epsilon: 0.0100; Mean (100): +15.32 *\n",
      "Epoch:13800; Score:  15.0; Epsilon: 0.0100; Mean (100): +15.84 *\n",
      "Epoch:13900; Score:  10.0; Epsilon: 0.0100; Mean (100): +14.98 *\n",
      "Epoch:14000; Score:  18.0; Epsilon: 0.0100; Mean (100): +15.71 *\n",
      "Epoch:14100; Score:  14.0; Epsilon: 0.0100; Mean (100): +14.57 *\n",
      "Epoch:14200; Score:  17.0; Epsilon: 0.0100; Mean (100): +14.64 *\n",
      "Epoch:14300; Score:   7.0; Epsilon: 0.0100; Mean (100): +15.28 *\n",
      "Epoch:14400; Score:  22.0; Epsilon: 0.0100; Mean (100): +14.81 *\n",
      "Epoch:14500; Score:  23.0; Epsilon: 0.0100; Mean (100): +14.31 *\n",
      "Epoch:14600; Score:  16.0; Epsilon: 0.0100; Mean (100): +15.13 *\n",
      "Epoch:14700; Score:  14.0; Epsilon: 0.0100; Mean (100): +15.00 *\n",
      "Epoch:14800; Score:  10.0; Epsilon: 0.0100; Mean (100): +14.19 *\n",
      "Epoch:14900; Score:  24.0; Epsilon: 0.0100; Mean (100): +14.77 *\n",
      "Epoch:15000; Score:  15.0; Epsilon: 0.0100; Mean (100): +13.86 *\n",
      "Epoch:15100; Score:  16.0; Epsilon: 0.0100; Mean (100): +15.32 *\n",
      "Epoch:15200; Score:  16.0; Epsilon: 0.0100; Mean (100): +14.20 *\n",
      "Epoch:15300; Score:   7.0; Epsilon: 0.0100; Mean (100): +14.48 *\n",
      "Epoch:15400; Score:  19.0; Epsilon: 0.0100; Mean (100): +14.71 *\n",
      "Epoch:15500; Score:  11.0; Epsilon: 0.0100; Mean (100): +15.41 *\n",
      "Epoch:15600; Score:  15.0; Epsilon: 0.0100; Mean (100): +15.67 *\n",
      "Epoch:15700; Score:  13.0; Epsilon: 0.0100; Mean (100): +15.23 *\n",
      "Epoch:15800; Score:  14.0; Epsilon: 0.0100; Mean (100): +13.72 *\n",
      "Epoch:15900; Score:  20.0; Epsilon: 0.0100; Mean (100): +14.64 *\n",
      "Epoch:16000; Score:  19.0; Epsilon: 0.0100; Mean (100): +14.30 *\n",
      "Epoch:16100; Score:  10.0; Epsilon: 0.0100; Mean (100): +13.37 *\n",
      "Epoch:16200; Score:  12.0; Epsilon: 0.0100; Mean (100): +13.50 *\n",
      "Epoch:16300; Score:  16.0; Epsilon: 0.0100; Mean (100): +13.40 *\n",
      "Epoch:16400; Score:  10.0; Epsilon: 0.0100; Mean (100): +13.62 *\n",
      "Epoch:16500; Score:  15.0; Epsilon: 0.0100; Mean (100): +13.72 *\n",
      "Epoch:16600; Score:  13.0; Epsilon: 0.0100; Mean (100): +13.87 *\n",
      "Epoch:16700; Score:  16.0; Epsilon: 0.0100; Mean (100): +14.39 *\n",
      "Epoch:16800; Score:  10.0; Epsilon: 0.0100; Mean (100): +15.00 *\n",
      "Epoch:16900; Score:   6.0; Epsilon: 0.0100; Mean (100): +14.38 *\n",
      "Epoch:17000; Score:  10.0; Epsilon: 0.0100; Mean (100): +14.84 *\n",
      "Epoch:17100; Score:   9.0; Epsilon: 0.0100; Mean (100): +14.62 *\n",
      "Epoch:17200; Score:  16.0; Epsilon: 0.0100; Mean (100): +14.47 *\n",
      "Epoch:17300; Score:  18.0; Epsilon: 0.0100; Mean (100): +13.78 *\n",
      "Epoch:17400; Score:  19.0; Epsilon: 0.0100; Mean (100): +14.22 *\n",
      "Epoch:17500; Score:  11.0; Epsilon: 0.0100; Mean (100): +14.24 *\n",
      "Epoch:17600; Score:  15.0; Epsilon: 0.0100; Mean (100): +14.24 *\n",
      "Epoch:17700; Score:  18.0; Epsilon: 0.0100; Mean (100): +15.53 *\n",
      "Epoch:17800; Score:  16.0; Epsilon: 0.0100; Mean (100): +15.53 *\n",
      "Epoch:17900; Score:  16.0; Epsilon: 0.0100; Mean (100): +13.93 *\n",
      "Epoch:18000; Score:  14.0; Epsilon: 0.0100; Mean (100): +14.37 *\n",
      "Epoch:18100; Score:  13.0; Epsilon: 0.0100; Mean (100): +14.39 *\n",
      "Epoch:18200; Score:  18.0; Epsilon: 0.0100; Mean (100): +15.38 *\n",
      "Epoch:18300; Score:  12.0; Epsilon: 0.0100; Mean (100): +14.91 *\n",
      "Epoch:18400; Score:  17.0; Epsilon: 0.0100; Mean (100): +14.50 *\n",
      "Epoch:18500; Score:  22.0; Epsilon: 0.0100; Mean (100): +15.45 *\n",
      "Epoch:18600; Score:  17.0; Epsilon: 0.0100; Mean (100): +14.36 *\n",
      "Epoch:18700; Score:  20.0; Epsilon: 0.0100; Mean (100): +14.28 *\n",
      "Epoch:18800; Score:  12.0; Epsilon: 0.0100; Mean (100): +14.10 *\n",
      "Epoch:18900; Score:  23.0; Epsilon: 0.0100; Mean (100): +13.42 *\n",
      "Epoch:19000; Score:   5.0; Epsilon: 0.0100; Mean (100): +13.47 *\n",
      "Epoch:19100; Score:  15.0; Epsilon: 0.0100; Mean (100): +14.11 *\n",
      "Epoch:19200; Score:  17.0; Epsilon: 0.0100; Mean (100): +15.14 *\n",
      "Epoch:19300; Score:  16.0; Epsilon: 0.0100; Mean (100): +15.34 *\n",
      "Epoch:19400; Score:  10.0; Epsilon: 0.0100; Mean (100): +15.44 *\n",
      "Epoch:19500; Score:  12.0; Epsilon: 0.0100; Mean (100): +13.96 *\n",
      "Epoch:19600; Score:  11.0; Epsilon: 0.0100; Mean (100): +14.39 *\n",
      "Epoch:19700; Score:  14.0; Epsilon: 0.0100; Mean (100): +14.53 *\n",
      "Epoch:19800; Score:  18.0; Epsilon: 0.0100; Mean (100): +14.30 *\n",
      "Epoch:19900; Score:  19.0; Epsilon: 0.0100; Mean (100): +13.96 *\n",
      "Epoch:20000; Score:  16.0; Epsilon: 0.0100; Mean (100): +14.85 *\n"
     ]
    }
   ],
   "source": [
    "scores = []  # List with all scores per episode\n",
    "scores_100_mean = 0 # Mean score over the last 100 episodes\n",
    "\n",
    "NUM_EPISODES = 20000\n",
    "CRIT_SOLVED = 999 #How many Bananas must be collected to succeed?\n",
    "\n",
    "epsilon = get_epsilon_i(NUM_EPISODES, evaluate = False)\n",
    "\n",
    "for epc in range(NUM_EPISODES):\n",
    "\n",
    "    env_info = env.reset(train_mode=True)[brain_name]  # reset the environment\n",
    "    state = env_info.vector_observations[0]            # get the current state\n",
    "    score = 0     # initialize the score\n",
    "    \n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    while True:\n",
    "        action = agent.act(state, epsilon[epc])        # select an action\n",
    "        env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "        next_state = env_info.vector_observations[0]   # get the next state\n",
    "        reward = env_info.rewards[0]                   # get the reward\n",
    "        done = env_info.local_done[0]                  # see if episode has finished\n",
    "        agent.step(state, action, reward, next_state, done)\n",
    "        score += reward                                # update the score\n",
    "        state = next_state                             # roll over the state to next time step\n",
    "        if done:                                       # exit loop if episode finished\n",
    "            break\n",
    "\n",
    "    scores.append(score)\n",
    "    if len(scores) >= 100:\n",
    "        scores_100_mean = np.mean( scores[-100:] )\n",
    "        \n",
    "    \n",
    "    stop_time = time.time()\n",
    "\n",
    "    print( '\\rEpoch:{:>5}; Score: {:>5}; Epsilon: {:2.4f}; Mean (100): {:+3.2f}'.format( epc+1, score, epsilon[epc], scores_100_mean ), \\\n",
    "          end = ' ')\n",
    "    if ( epc+1 ) % 100 == 0:       \n",
    "        print('*')\n",
    "        \n",
    "    if (scores_100_mean > CRIT_SOLVED):\n",
    "        print('#')\n",
    "        # print( 'Udacity criterion reached (Mean of recent 100 runs > 13), enviroment is considered as solved!')\n",
    "        print( 'My criterion reached (Mean of recent 100 runs > '+ str(CRIT_SOLVED) +'), enviroment is considered as solved!')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(scores)\n",
    "plt.ylabel('Training scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp is: 20200707090905\n"
     ]
    }
   ],
   "source": [
    "# Thx2: https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "\n",
    "import torch\n",
    "\n",
    "timestamp = get_time_string()\n",
    "torch.save(agent.qnetwork_local.state_dict(), './output/' + timestamp + '_qnetwork_local_statedict.pth')\n",
    "print('Timestamp is: ' + timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watch the trained agent in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dql_agent import Agent\n",
    "\n",
    "agent = Agent(state_size, action_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# FA The network from my GPU training run did not load\n",
    "# Thx 2: https://stackoverflow.com/a/55759312\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    map_location=lambda storage, loc: storage.cuda()\n",
    "    print('CUDA')\n",
    "else:\n",
    "    map_location='cpu'\n",
    "    print('CPU')\n",
    "    \n",
    "\n",
    "\n",
    "# load the weights from file\n",
    "agent.qnetwork_local.load_state_dict(torch.load('./output/20200706160011_qnetwork_local_statedict.pth', map_location=map_location))\n",
    "agent.qnetwork_local.eval() #Set Network in evaluation mode - important!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_sum = 0\n",
    "\n",
    "for epc in range(5):\n",
    "\n",
    "    env_info = env.reset(train_mode=False)[brain_name]  # reset the environment\n",
    "    state = env_info.vector_observations[0]            # get the current state\n",
    "    score = 0     # initialize the score\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    while True:\n",
    "        action = agent.act(state)        # select an action\n",
    "        env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "        next_state = env_info.vector_observations[0]   # get the next state\n",
    "        reward = env_info.rewards[0]                   # get the reward\n",
    "        done = env_info.local_done[0]                  # see if episode has finished\n",
    "        # agent.step(state, action, reward, next_state, done) # not step needed in evaluation\n",
    "        score += reward                                # update the score\n",
    "        state = next_state                             # roll over the state to next time step\n",
    "        if done:                                       # exit loop if episode finished\n",
    "            break\n",
    "\n",
    "    stop_time = time.time()\n",
    "    score_sum += score\n",
    "    print( \"Epoch:{:>5}; Score: {:>5}; Execution time: {:.4f}\".format( epc+1, score, stop_time - start_time ) )\n",
    "\n",
    "print( 'Achieved mean over {} test runs: {}'.format( ( epc+1 ), score_sum / (epc+1) ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
